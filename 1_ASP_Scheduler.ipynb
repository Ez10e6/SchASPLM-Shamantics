{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: BNB_CUDA_VERSION=123 environment variable detected; loading libbitsandbytes_cuda123.dll.\n",
      "This can be used to load a bitsandbytes version built with a CUDA version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA detected. Using NVIDIA configuration.\n",
      "Checking for model in ./local_models/Qwen/Qwen2.5-7B-Instruct...\n",
      "loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4589b6b262d4d8398617168e7e2d288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './local_models/Qwen/Qwen2.5-7B-Instruct' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for model in ./local_models/Qwen/Qwen2.5-7B-Instruct...\n",
      "loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2414d976ddeb4be2a0d6df2779fa89da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './local_models/Qwen/Qwen2.5-7B-Instruct' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Extracted semantics:\n",
      "- Every team Team exists.\n",
      "- Every venue Venue exists.\n",
      "- For every venue Venue, there is an availability on some Date.\n",
      "\n",
      "Intended semantics from prompt:\n",
      "\n",
      "- Teams: a set of teams that plays in the league\n",
      "    - Variables: team\n",
      "- Venues: a set of venues that is available\n",
      "    - Variables: venues\n",
      "- Availabilities: A set of dates at which a given venue is available \n",
      "    - Variables: venues, dates\n",
      "    \n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Semantics correctness check response:\n",
      "Yes\n",
      "\n",
      "Semantics correct: True\n",
      "\n",
      "================================================================================\n",
      "####################################################################################\n",
      "PROGRAM PART DID NOT NEED REPAIR!\n",
      "RESPONSE:\n",
      "team(Team).\n",
      "\n",
      "venue(Venue).\n",
      "\n",
      "availability(Venue, Date).\n",
      "\n",
      "####################################################################################\n",
      "Instance Template:\n",
      "team(Team).\n",
      "\n",
      "venue(Venue).\n",
      "\n",
      "availability(Venue, Date).\n",
      "================================================================================\n",
      "Initial response with syntax error:\n",
      "1 {{ game(Team1, Team2, Venue, GameDay) : team(Team1), team(Team2), venue(Venue), gameday(GameDay) }} 1 :- team(Team1), team(Team2), venue(Venue), gameday(GameDay).\n",
      "\n",
      "Error: <string>:1:4-5: error: syntax error, unexpected {\n",
      "\n",
      " Starting syntax repair attempts...\n",
      "================================================================================\n",
      "--------------------------------------------------------------------------------\n",
      "Correction attempt 1:\n",
      "{{ game(Team1, Team2, Venue, GameDay) : team(Team1), team(Team2), venue(Venue), gameday(GameDay) }} 1 :- team(Team1), team(Team2), venue(Venue), gameday(GameDay).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Syntax error still present: <string>:1:2-3: error: syntax error, unexpected {\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Correction attempt 2:\n",
      "{{ game(Team1, Team2, Venue, GameDay) : team(Team1), team(Team2), venue(Venue), gameday(GameDay) }} 1 :- team(Team1), team(Team2), venue(Venue), gameday(GameDay).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Syntax error still present: <string>:1:2-3: error: syntax error, unexpected {\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Correction attempt 3:\n",
      "{{ game(Team1, Team2, Venue, GameDay) : team(Team1), team(Team2), venue(Venue), gameday(GameDay) }} 1 :- team(Team1), team(Team2), venue(Venue), gameday(GameDay).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Syntax error still present: <string>:1:2-3: error: syntax error, unexpected {\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Correction attempt 4:\n",
      "{{ game(Team1, Team2, Venue, GameDay) : team(Team1), team(Team2), venue(Venue), gameday(GameDay) }} 1 :- team(Team1), team(Team2), venue(Venue), gameday(GameDay).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Syntax error still present: <string>:1:2-3: error: syntax error, unexpected {\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Correction attempt 5:\n",
      "{{ game(Team1, Team2, Venue, GameDay) : team(Team1), team(Team2), venue(Venue), gameday(GameDay) }} 1 :- team(Team1), team(Team2), venue(Venue), gameday(GameDay).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Syntax error still present: <string>:1:2-3: error: syntax error, unexpected {\n",
      "\n",
      "================================================================================\n",
      "Syntax errors remain after repair attempts. Cannot proceed to semantic checking.\n",
      "Total syntax errors: 1\n",
      "\n",
      "================================================================================\n",
      "####################################################################################\n",
      "PROGRAM PART WAS REPAIRED , BUT UNSUCCESSFULLY\n",
      "INITIAL RESPONSE:\n",
      "% Assignment of games to pairs of teams, venues and game days\n",
      "1 {{ game(Team1, Team2, Venue, GameDay) : team(Team1), team(Team2), venue(Venue), gameday(GameDay) }} 1 :- team(Team1), team(Team2), venue(Venue), gameday(GameDay).\n",
      "\n",
      "REPAIRED RESPONSE:\n",
      "% Assignment of games to pairs of teams, venues and game days\n",
      "{{ game(Team1, Team2, Venue, GameDay) : team(Team1), team(Team2), venue(Venue), gameday(GameDay) }} 1 :- team(Team1), team(Team2), venue(Venue), gameday(GameDay).\n",
      "\n",
      "Total syntax errors remaining after repair attempts: 1\n",
      "\n",
      "Semantics correct (according to LLM): False\n",
      "\n",
      "####################################################################################\n",
      "\n",
      "\n",
      "Generator\n",
      "% Assignment of games to pairs of teams, venues and game days\n",
      "{{ game(Team1, Team2, Venue, GameDay) : team(Team1), team(Team2), venue(Venue), gameday(GameDay) }} 1 :- team(Team1), team(Team2), venue(Venue), gameday(GameDay).\n",
      "\n",
      "\n",
      "Hard Constraints\n",
      "\n",
      "================================================================================\n",
      "Extracted semantics:\n",
      "- For every pair of teams Team1 and Team2, it is forbidden to have two games between Team1 and Team2 on different dates where the first date is earlier than the second date.\n",
      "\n",
      "Intended semantics from prompt:\n",
      "- No team plays each other more than once at different gamedays.\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Semantics correctness check response:\n",
      "Yes\n",
      "\n",
      "Semantics correct: True\n",
      "\n",
      "================================================================================\n",
      "####################################################################################\n",
      "PROGRAM PART DID NOT NEED REPAIR!\n",
      "RESPONSE:\n",
      ":- game(Team1, Team2, _, GameDay1), game(Team1, Team2, _, GameDay2), GameDay1 < GameDay2.\n",
      "\n",
      "####################################################################################\n",
      "- No team plays each other more than once at different gamedays.\n",
      ":- game(Team1, Team2, _, GameDay1), game(Team1, Team2, _, GameDay2), GameDay1 < GameDay2.\n",
      "\n",
      "================================================================================\n",
      "Extracted semantics:\n",
      "- There exists no game between Team1 and Team2.\n",
      "- There exists no game between Team1 and Team3.\n",
      "- There exists no game between Team2 and Team3.\n",
      "- There exists no game between Team1 and Team3 on any venue or day.\n",
      "- There exists no game between Team1 and Team2 on any venue or day.\n",
      "- There exists no game between Team2 and Team3 on any venue or day.\n",
      "\n",
      "Intended semantics from prompt:\n",
      "- Every team plays every other team at least once.\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Semantics correctness check response:\n",
      "No\n",
      "\n",
      "Semantics correct: False\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Semantics are incorrect. Starting semantic repair attempts...\n",
      "================================================================================\n",
      "================================================================================\n",
      "Extracted semantics:\n",
      "- There exists no game between Team1 and Team2.\n",
      "- There exists no game between Team1 and Team3.\n",
      "- There exists no game between Team2 and Team3.\n",
      "\n",
      "Intended semantics from prompt:\n",
      "- Every team plays every other team at least once.\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Semantics correctness check response:\n",
      "No\n",
      "\n",
      "Semantics correct: False\n",
      "\n",
      "================================================================================\n",
      "--------------------------------------------------------------------------------\n",
      "Semantic repair attempt 1:\n",
      ":- team(Team1), team(Team2), game(Team1, Team2, _, _), game(Team1, Team2, _, _).\n",
      ":- team(Team1), team(Team3), game(Team1, Team3, _, _), game(Team1, Team3, _, _).\n",
      ":- team(Team2), team(Team3), game(Team2, Team3, _, _), game(TTeam2, Team3, _, _).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Extracted semantics:\n",
      "- There exists no two games between Team1 and Team2.\n",
      "- There exists no two games between Team1 and Team3.\n",
      "- There exist no two games between Team2 and Team3.\n",
      "\n",
      "Intended semantics from prompt:\n",
      "- Every team plays every other team at least once.\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Semantics correctness check response:\n",
      "No\n",
      "\n",
      "Semantics correct: False\n",
      "\n",
      "================================================================================\n",
      "--------------------------------------------------------------------------------\n",
      "Semantic repair attempt 2:\n",
      ":- team(Team1), team(Team2), game(Team1, Team2, _, _), game(Team1, Team2, _, _).\n",
      ":- team(Team1), team(Team3), game(Team1, Team3, _, _), game(Team1, Team3, _, _).\n",
      ":- team(Team2), team(Team3), game(Team2, Team3, _, _), game(Team2, Team3, _, _).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "####################################################################################\n",
      "PROGRAM PART WAS REPAIRED SUCCESSFULLY\n",
      "INITIAL RESPONSE:\n",
      ":- team(Team1), team(Team2), team(Team3), game(Team1, Team2, _, _), game(Team1, Team3, _, _), game(Team2, Team3, _, _), not game(Team1, Team2, _, _), not game(Team1, Team3, _, _), not game(Team2, Team3, _, _).\n",
      "\n",
      "REPAIRED RESPONSE:\n",
      ":- team(Team1), team(Team2), game(Team1, Team2, _, _), game(Team1, Team2, _, _).\n",
      ":- team(Team1), team(Team3), game(Team1, Team3, _, _), game(Team1, Team3, _, _).\n",
      ":- team(Team2), team(Team3), game(Team2, Team3, _, _), game(Team2, Team3, _, _).\n",
      "\n",
      "Total syntax errors remaining after repair attempts: 0\n",
      "\n",
      "Semantics correct (according to LLM): False\n",
      "\n",
      "####################################################################################\n",
      "- Every team plays every other team at least once.\n",
      ":- team(Team1), team(Team2), game(Team1, Team2, _, _), game(Team1, Team2, _, _).\n",
      ":- team(Team1), team(Team3), game(Team1, Team3, _, _), game(Team1, Team3, _, _).\n",
      ":- team(Team2), team(Team3), game(Team2, Team3, _, _), game(Team2, Team3, _, _).\n",
      "\n",
      "================================================================================\n",
      "Extracted semantics:\n",
      "- For every team Team, it is forbidden to have a game where Team plays against itself on any game day.\n",
      "\n",
      "Intended semantics from prompt:\n",
      "- No team plays itself.\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Semantics correctness check response:\n",
      "Yes\n",
      "\n",
      "Semantics correct: True\n",
      "\n",
      "================================================================================\n",
      "####################################################################################\n",
      "PROGRAM PART DID NOT NEED REPAIR!\n",
      "RESPONSE:\n",
      ":- team(Team), game(Team, Team, _, _).\n",
      "\n",
      "####################################################################################\n",
      "- No team plays itself.\n",
      ":- team(Team), game(Team, Team, _, _).\n",
      "\n",
      "\n",
      "Soft Constraints:\n",
      "\n",
      "================================================================================\n",
      "Extracted semantics:\n",
      "- Assigning a team to play against an opponent at two different venues on the same day incurs a penalty of 1 for the \"VenueSwitch\" penalty.\n",
      "- The penalty \"VenueSwitch\" applies when a team plays against the same opponent at two different venues on the same day.\n",
      "- The penalty is triggered if and only if the team plays against the opponent at two different venues (Venue1 and Venue2) on the same game day (GameDay), and Venue1 is not equal to Venue2.\n",
      "\n",
      "Intended semantics from prompt:\n",
      "- Teams should play at the same venue as little as possible.\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Semantics correctness check response:\n",
      "Yes\n",
      "\n",
      "Semantics correct: True\n",
      "\n",
      "================================================================================\n",
      "####################################################################################\n",
      "PROGRAM PART DID NOT NEED REPAIR!\n",
      "RESPONSE:\n",
      "penalty(\"VenueSwitch\",using_venues(Team,Venue1,Venue2),1) :- game(Team,Opponent,Venue1,GameDay), game(Team,Opponent,Venue2,GameDay), Venue1!= Venue2.\n",
      "\n",
      "####################################################################################\n",
      "- Teams should play at the same venue as little as possible.\n",
      "penalty(\"VenueSwitch\",using_venues(Team,Venue1,Venue2),1) :- game(Team,Opponent,Venue1,GameDay), game(Team,Opponent,Venue2,GameDay), Venue1!= Venue2.\n",
      "\n",
      "Full program saved to Results/temp\\sports scheduling_Qwen2.5-7B-Instruct (quant 4bit)_k=5_20251229_133316.lp\n"
     ]
    }
   ],
   "source": [
    "# We illustrate the generation of a scheduling problem using a local model  (using chain-of-thought and few-shot prompting)\n",
    "# Notice you have to have your api-key under .env\n",
    "\n",
    "# Doing all the imports in this cell because each local GPU run needs a kernel restart. \n",
    "# Without a kernel restart, CPU is used instead of GPU after loading a local model once.\n",
    "from LLM import bots\n",
    "from ASP_Scheduler.problem_descriptions import all_problems\n",
    "from ASP_Scheduler import scheduler\n",
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from utils import logger\n",
    "\n",
    "###########################################################\n",
    "#                        SETTINGS                         #\n",
    "###########################################################\n",
    "\n",
    "# GENERAL SETTINGS\n",
    "RUN_LOCAL_MODEL = True         # Set to True to run a local model, False to run a remote model via OpenAI API\n",
    "PRINT = True                    # Set to True to print intermediate outputs\n",
    "PROGRAM_FOLDER = 'Results/temp'     # Folder to save programs (set to None to disable saving)\n",
    "METRICS_LOG_FILE = 'metrics/metrics.csv'\n",
    "\n",
    "# REMOTE SETTINGS\n",
    "# REMOTE_PIPE = None # None defaults to meta-llama/Meta-Llama-3-8B-Instruct\n",
    "# REMOTE_PIPE = 'deepseek' # 'deepseek' model on OpenAI API\n",
    "# REMOTE_PIPE_SEMANTICS = None # None defaults to meta-llama/Meta-Llama-3-8B-Instruct\n",
    "# REMOTE_PIPE_SEMANTICS = 'deepseek' # 'deepseek' model on OpenAI API\n",
    "\n",
    "# LOCAL SETTINGS\n",
    "#CHECKPOINT, CHECKPOINT_SHORT_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\", \"Llama-3-8B-Instruct\" \n",
    "CHECKPOINT, CHECKPOINT_SHORT_NAME = \"Qwen/Qwen2.5-7B-Instruct\", \"Qwen2.5-7B-Instruct\"\n",
    "#CHECKPOINT_SEMANTICS, CHECKPOINT_SHORT_NAME_SEMANTICS = \"meta-llama/Meta-Llama-3-8B-Instruct\", \"Llama-3-8B-Instruct\" \n",
    "CHECKPOINT_SEMANTICS, CHECKPOINT_SHORT_NAME_SEMANTICS = \"Qwen/Qwen2.5-7B-Instruct\", \"Qwen2.5-7B-Instruct\"\n",
    "\n",
    "# DYNAMIC HARDWARE CONFIGURATION\n",
    "if torch.cuda.is_available():\n",
    "    # Settings for NVIDIA GPUs\n",
    "    print(\"CUDA detected. Using NVIDIA configuration.\")\n",
    "    os.environ[\"BNB_CUDA_VERSION\"] = \"123\"  # Force bnb version for Windows/Cuda if needed\n",
    "    QUANTIZATION_CONFIG = '4bit'          # '4bit', '8bit' supported on CUDA\n",
    "else:\n",
    "    # Settings for Mac (MPS) or CPU\n",
    "    print(\"CUDA not detected. Using MPS/CPU configuration (Quantization disabled).\")\n",
    "    QUANTIZATION_CONFIG = None            # bitsandbytes quantization is not supported on MPS yet\n",
    "\n",
    "# SAMPLING / REPRODUCIBILITY SETTINGS\n",
    "# - Set SEED = -1 to disable fixed seeding (non-deterministic runs). Set to an integer for reproducible runs.\n",
    "SEED = -1\n",
    "MAX_NEW_TOKENS = 512 #Max tokens for response. Should be in balance with the model's context size\n",
    "\n",
    "# TEMPERATURE = 0.2  # Less deterministic\n",
    "# TOP_P = 0.9        # Less deterministic\n",
    "TEMPERATURE = 0.01 # More deterministic (same as local settings of original experiments)\n",
    "TOP_P = 0          # More deterministic (same as local settings of original experiments)\n",
    "\n",
    "# PROBLEM SETTINGS\n",
    "PROBLEM_NAMES = ['sports scheduling']\n",
    "# PROBLEM_NAMES = ['nurse_scheduling']\n",
    "# PROBLEM_NAMES = ['nurse_scheduling', 'sports scheduling']\n",
    "# PROBLEM_NAMES = ['post_enrollment_based_course_time_tabling', 'examination_timetabling']\n",
    "# PROBLEM_NAMES = list(all_problems.keys())  # To run the program for ALL available problem names\n",
    "MAX_SYNTAX_REPAIRS = 5  # Maximum number of repair attempts per statement block for syntax errors\n",
    "MAX_SEMANTIC_REPAIRS = 2  # Maximum number of repair attempts per statement block for semantic errors\n",
    "RUNS_PER_PROBLEM = 1  # Number of runs per problem for averaging results\n",
    "\n",
    "if RUN_LOCAL_MODEL:\n",
    "    # To work locally, we need to manually load the pipeline \n",
    "    PIPE = bots.load_pipe(model_checkpoint=CHECKPOINT, local_dir=\"./local_models\", quantization_config=QUANTIZATION_CONFIG, save=True)\n",
    "    SEMANTICS_PIPE = bots.load_pipe(model_checkpoint=CHECKPOINT_SEMANTICS, local_dir=\"./local_models\", quantization_config=QUANTIZATION_CONFIG, save=True)  \n",
    "else:\n",
    "    # For remote models, we set pipe to a string with the model name\n",
    "    PIPE = REMOTE_PIPE\n",
    "    SEMANTICS_PIPE = REMOTE_PIPE_SEMANTICS\n",
    "\n",
    "# Run the LLM scheduler per problem\n",
    "for problem_name in PROBLEM_NAMES:\n",
    "    for run_id in range(RUNS_PER_PROBLEM):        \n",
    "        # Initialize the metrics logger\n",
    "        # Build a model identifier string for the logfile (include LOCAL/REMOTE)\n",
    "        model_id = (f\"{CHECKPOINT} (LOCAL, QUANTIZATION: {QUANTIZATION_CONFIG})\" if RUN_LOCAL_MODEL else (f\"{REMOTE_PIPE} (REMOTE)\" if REMOTE_PIPE is not None else \"Meta-Llama-3-8B-Instruct\"))\n",
    "        semantics_model_id = (f\"{CHECKPOINT_SEMANTICS} (LOCAL, QUANTIZATION: {QUANTIZATION_CONFIG})\" if RUN_LOCAL_MODEL else (f\"{REMOTE_PIPE_SEMANTICS} (REMOTE)\" if REMOTE_PIPE_SEMANTICS is not None else \"Meta-Llama-3-8B-Instruct\"))\n",
    "        logger.init_logger(filename=METRICS_LOG_FILE,\n",
    "                           problem_ID=problem_name,\n",
    "                           max_fix_attempts=MAX_SYNTAX_REPAIRS,\n",
    "                           model=model_id,\n",
    "                           semantics_model=semantics_model_id,\n",
    "                           temperature=TEMPERATURE,\n",
    "                           top_p=TOP_P,\n",
    "                           seed=SEED)\n",
    "\n",
    "        full_program = scheduler.full_ASP_program(\n",
    "            all_problems[problem_name],    # Input problem specifications for examination timetabling\n",
    "            pipe=PIPE,                     # Input the PIPEline object for the LLM\n",
    "            semantic_validation_pipe=SEMANTICS_PIPE, # Input the PIPEline object for the semantics validation LLM\n",
    "            printer=PRINT,                 # Set to True to print intermediate outputs\n",
    "            k=MAX_SYNTAX_REPAIRS,                 # Max repairs\n",
    "            n=MAX_SEMANTIC_REPAIRS,                 # Max repairs\n",
    "            temperature=TEMPERATURE,\n",
    "            top_p=TOP_P,\n",
    "            seed=(None if SEED == -1 else SEED),\n",
    "            max_new_tokens=MAX_NEW_TOKENS)\n",
    "                            \n",
    "\n",
    "        if PROGRAM_FOLDER is not None:\n",
    "            # Save the full program to a file\n",
    "            os.makedirs(PROGRAM_FOLDER, exist_ok=True)\n",
    "            timestamp = logger.time_stamp()\n",
    "            if RUN_LOCAL_MODEL:\n",
    "                model_string = CHECKPOINT_SHORT_NAME\n",
    "                if QUANTIZATION_CONFIG is not None:\n",
    "                    # Append quantization info like \" (quant 4bit)\" or \" (quant 8bit)\"\n",
    "                    model_string = f\"{model_string} (quant {QUANTIZATION_CONFIG})\"\n",
    "            else:\n",
    "                model_string = REMOTE_PIPE if REMOTE_PIPE is not None else \"Meta-Llama-3-8B-Instruct\"\n",
    "            max_repairs_string = f\"_k={MAX_SYNTAX_REPAIRS}\" if MAX_SYNTAX_REPAIRS is not None else \"\"\n",
    "            program_filename = os.path.join(PROGRAM_FOLDER, f\"{problem_name}_{model_string}{max_repairs_string}_{timestamp}.lp\")\n",
    "            with open(program_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(full_program)\n",
    "            if PRINT:\n",
    "                print(f\"Full program saved to {program_filename}\")\n",
    "        else:\n",
    "            # Print the full program as it is returned by the scheduler\n",
    "            print('----------------------------FULL PROGRAM----------------------------')\n",
    "            print(full_program)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
